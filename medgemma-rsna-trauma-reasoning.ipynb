{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6684057,"sourceType":"datasetVersion","datasetId":3629278}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:35:04.121926Z","iopub.execute_input":"2026-01-15T21:35:04.122941Z","iopub.status.idle":"2026-01-15T21:35:04.489622Z","shell.execute_reply.started":"2026-01-15T21:35:04.122895Z","shell.execute_reply":"2026-01-15T21:35:04.488570Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install -U bitsandbytes  \n!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:35:06.178537Z","iopub.execute_input":"2026-01-15T21:35:06.179430Z","iopub.status.idle":"2026-01-15T21:35:19.434182Z","shell.execute_reply.started":"2026-01-15T21:35:06.179393Z","shell.execute_reply":"2026-01-15T21:35:19.433201Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0rc2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.49.1\nCollecting ultralytics\n  Downloading ultralytics-8.4.2-py3-none-any.whl.metadata (36 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.4.2-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.4.2 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q -U transformers accelerate peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:35:38.964337Z","iopub.execute_input":"2026-01-15T21:35:38.964672Z","iopub.status.idle":"2026-01-15T21:35:43.559592Z","shell.execute_reply.started":"2026-01-15T21:35:38.964619Z","shell.execute_reply":"2026-01-15T21:35:43.557996Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN2\")\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:35:47.433967Z","iopub.execute_input":"2026-01-15T21:35:47.435021Z","iopub.status.idle":"2026-01-15T21:35:48.386765Z","shell.execute_reply.started":"2026-01-15T21:35:47.434943Z","shell.execute_reply":"2026-01-15T21:35:48.385860Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:35:57.651964Z","iopub.execute_input":"2026-01-15T21:35:57.652808Z","iopub.status.idle":"2026-01-15T21:35:57.669165Z","shell.execute_reply.started":"2026-01-15T21:35:57.652779Z","shell.execute_reply":"2026-01-15T21:35:57.668243Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0077fa3ab5d44051b11066dfdf9fe5bb"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"%%time\nimport torch\nfrom transformers import AutoProcessor, AutoModelForImageTextToText\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# 1. Secure Authentication\nuser_secrets = UserSecretsClient()\ntry:\n    hf_token = user_secrets.get_secret(\"HF_TOKEN2\")\n    login(token=hf_token)\n    print(\"‚úÖ Login Successful\")\nexcept:\n    print(\"‚ùå Error: HF_TOKEN not found in Kaggle Secrets.\")\n\n# 2. Resource Management Logic\nmodel_id = \"google/medgemma-1.5-4b-it\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"üöÄ Initializing model on: {device.upper()}\")\n\n# 3. Load Model (Optimized for CPU/GPU)\nprocessor = AutoProcessor.from_pretrained(model_id)\n\nif device == \"cuda\":\n    # GPU Mode: Fast 4-bit quantization\n    model = AutoModelForImageTextToText.from_pretrained(\n        model_id,\n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\",\n        load_in_4bit=True\n    )\nelse:\n    # CPU Mode: Save your 30hr quota by using full RAM\n    print(\"‚ÑπÔ∏è GPU not detected. Running in CPU mode (Debugging only).\")\n    model = AutoModelForImageTextToText.from_pretrained(\n        model_id,\n        torch_dtype=torch.float32,\n        device_map=\"cpu\"\n    )\n\nprint(f\"üéâ Model Loaded Successfully on {device}!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:36:03.614478Z","iopub.execute_input":"2026-01-15T21:36:03.615345Z","iopub.status.idle":"2026-01-15T21:37:32.565308Z","shell.execute_reply.started":"2026-01-15T21:36:03.615310Z","shell.execute_reply":"2026-01-15T21:37:32.564161Z"}},"outputs":[{"name":"stderr","text":"2026-01-15 21:36:15.003354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768512975.209601      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768512975.270728      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768512975.772394      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768512975.772449      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768512975.772452      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768512975.772454      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Login Successful\nüöÄ Initializing model on: CUDA\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7500b5d092049c596b11c5a090f9057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7569569c0241ca873e69445e0b880f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be62162ada8a4212b77df1113e309295"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf0ba5c7a544bd99b9ca2434740a968"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4461bee1d6944be6a7c500459880e0e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ad72c36c4d4b6881ac2b26d4a69279"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daea08420bf2406fa435ff0965467933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d09a0c1c2bae4aea87633726f5e1b774"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af1687887e14473fb101f4c50696ab0d"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\nThe `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a36dd0a9243f4e8b836ea188f11e3e58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f356fc8132154d6e9df8fdbff5abccc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ad3639cd2f4694b8e349b0518f25a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8fcc5d25c64441aa5b7e796bb88bed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f501d7de73f24f84bd455ae1cd118aa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a16d4ca45581434b97904cc72abec62b"}},"metadata":{}},{"name":"stdout","text":"üéâ Model Loaded Successfully on cuda!\nCPU times: user 1min 13s, sys: 42.8 s, total: 1min 55s\nWall time: 1min 28s\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%time\nimport torch\nfrom transformers import pipeline\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\n# 1. Update your image loading logic\nurl = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n}\n\npipe = pipeline(\n    \"image-text-to-text\", \n    model=\"google/medgemma-1.5-4b-it\", \n    torch_dtype=torch.bfloat16, \n    device_map=\"auto\",\n    model_kwargs={\"load_in_4bit\": True} # Save VRAM for large datasets\n)\n\n\nresponse = requests.get(url, headers=headers)\nif response.status_code == 200:\n    # Use BytesIO to handle the raw content safely\n    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n    print(\"‚úÖ Image loaded and converted to RGB successfully.\")\nelse:\n    print(f\"‚ùå Failed to download image. Status code: {response.status_code}\")\n\n# 2. Run your inference again\n# (Using the prompt and messages from our previous step)\nprompt = \"\"\"Analyze this chest X-ray as a senior radiologist. \n1. Identify key anatomical landmarks.\n2. Note any abnormal opacities or findings.\n3. Provide a summary of the clinical impression.\"\"\"\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": image},\n            {\"type\": \"text\", \"text\": prompt},\n        ],\n    },\n]\n\n# Run the pipeline (ensure 'pipe' is defined from our previous step)\noutput = pipe(messages, max_new_tokens=512)\nprint(\"-\" * 30)\nprint(output[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:37:56.104459Z","iopub.execute_input":"2026-01-15T21:37:56.105601Z","iopub.status.idle":"2026-01-15T21:38:44.180856Z","shell.execute_reply.started":"2026-01-15T21:37:56.105562Z","shell.execute_reply":"2026-01-15T21:38:44.180059Z"}},"outputs":[{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\nThe `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"152ae5e44d114b12aa98a6740d45dbd4"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nSetting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Image loaded and converted to RGB successfully.\n------------------------------\n[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=2412x1956 at 0x7A18B66202C0>}, {'type': 'text', 'text': 'Analyze this chest X-ray as a senior radiologist. \\n1. Identify key anatomical landmarks.\\n2. Note any abnormal opacities or findings.\\n3. Provide a summary of the clinical impression.'}]}, {'role': 'assistant', 'content': \"Here's an analysis of the provided chest X-ray:\\n\\n1.  **Anatomical Landmarks:**\\n    *   **Heart:** Appears normal in size and contour.\\n    *   **Mediastinum:** Normal in width and appearance.\\n    *   **Ribs:** Visible and appear intact.\\n    *   **Clavicles:** Visible.\\n    *   **Diaphragm:** The right hemidiaphragm is visible.\\n    *   **Lungs:** The lung fields are clear with good visualization of the lung markings.\\n\\n2.  **Abnormalities:**\\n    *   **No significant abnormalities** are immediately apparent on this single image.\\n\\n3.  **Clinical Impression:**\\n    *   Based on the image, the patient appears to have a normal chest X-ray. The lung fields are clear, the heart size is within normal limits, and there are no obvious signs of acute pathology.\\n\\n**Disclaimer:** This analysis is based solely on the provided image. A complete clinical evaluation would require patient history, physical examination findings, and potentially other imaging studies. A radiologist would consider this image within the context of the patient's overall clinical picture to provide a definitive diagnosis.\"}]\nCPU times: user 41.8 s, sys: 4.76 s, total: 46.5 s\nWall time: 48.1 s\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%time\nimport os\nfrom PIL import Image\n\n# 1. Path to one of the JPGs in your added dataset\ntest_image_path = '/kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/yolov8_roi_detection/experiment/val_batch0_pred.jpg'\n\nif os.path.exists(test_image_path):\n    # 2. Load the image\n    test_img = Image.open(test_image_path).convert(\"RGB\")\n    print(f\"‚úÖ Loaded test image: {test_image_path}\")\n\n    # 3. MedGemma Prompt\n    # Since these are YOLO predictions, we can ask the model to describe the boxes it sees.\n    prompt = \"This is a CT slice with YOLO detection boxes. Describe the organs identified and check for any signs of injury inside the boxes.\"\n\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image\", \"image\": test_img},\n                {\"type\": \"text\", \"text\": prompt},\n            ],\n        },\n    ]\n\n    # 4. Inference\n    print(\"üöÄ Testing MedGemma reasoning...\")\n    output = pipe(messages, max_new_tokens=256)\n    print(\"\\nü©∫ ANALYSIS:\\n\", output[0]['generated_text'])\nelse:\n    print(\"‚ùå Still can't find that image. Let's list the input directory to be sure.\")\n    print(os.listdir('/kaggle/input/'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:42:40.680447Z","iopub.execute_input":"2026-01-15T21:42:40.681553Z","iopub.status.idle":"2026-01-15T21:43:08.194909Z","shell.execute_reply.started":"2026-01-15T21:42:40.681517Z","shell.execute_reply":"2026-01-15T21:43:08.193885Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Loaded test image: /kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/yolov8_roi_detection/experiment/val_batch0_pred.jpg\nüöÄ Testing MedGemma reasoning...\n\nü©∫ ANALYSIS:\n [{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1920x1808 at 0x7A18B67CB4D0>}, {'type': 'text', 'text': 'This is a CT slice with YOLO detection boxes. Describe the organs identified and check for any signs of injury inside the boxes.'}]}, {'role': 'assistant', 'content': \"This is a CT slice image showing anatomical structures, likely from a veterinary or veterinary medicine context, based on the labels. The image displays several regions and organs.\\n\\nHere's a breakdown of the identified organs and potential observations:\\n\\n**Abdominal and Thoracic Regions:**\\n*   **Abdominal:** The image shows the abdomen region, with several structures visible, including intestines, the liver, and the kidneys.\\n*   **Lower:** This likely refers to the lower portion of the image, which could represent the caudal (tail) region and organs like the bladder and rectum.\\n\\n**Based on the image, these are the organs identified:**\\n\\n*   **Intestines:** The image displays sections of intestines in the abdominal regions.\\n*   **Liver:** A portion of the liver is visible.\\n*   **Kidneys:** The kidneys are visible in the upper abdominal region.\\n*   **Bladder:** In the lower abdominal region, there seems to be a bladder with some signs of fluid.\\n*   **Rectum:** Rectum is visible in the lower abdominal region.\\n\\n**Potential signs of injury:**\\n*   There are no obvious signs of severe trauma or injury evident in the image, but further evaluation requires a more comprehensive understanding\"}]\nCPU times: user 27.2 s, sys: 347 ms, total: 27.5 s\nWall time: 27.5 s\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Updated Clinical Prompt\nclinical_prompt = \"\"\"You are a senior trauma radiologist assistant. \nReview the bounding boxes in this CT scan specifically for:\n1. Lacerations or hematomas in the Liver/Spleen.\n2. Active extravasation (bright contrast pooling).\n3. Free fluid in the peritoneal cavity.\n\nIdentify the findings in the highlighted ROIs and categorize them by organ.\"\"\"\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\", \"image\": test_img},\n            {\"type\": \"text\", \"text\": clinical_prompt},\n        ],\n    },\n]\n\n# Run it again\noutput = pipe(messages, max_new_tokens=512)\nprint(output[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:45:25.051200Z","iopub.execute_input":"2026-01-15T21:45:25.051592Z","iopub.status.idle":"2026-01-15T21:45:45.942573Z","shell.execute_reply.started":"2026-01-15T21:45:25.051562Z","shell.execute_reply":"2026-01-15T21:45:45.941771Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1920x1808 at 0x7A18B67CB4D0>}, {'type': 'text', 'text': 'You are a senior trauma radiologist assistant. \\nReview the bounding boxes in this CT scan specifically for:\\n1. Lacerations or hematomas in the Liver/Spleen.\\n2. Active extravasation (bright contrast pooling).\\n3. Free fluid in the peritoneal cavity.\\n\\nIdentify the findings in the highlighted ROIs and categorize them by organ.'}]}, {'role': 'assistant', 'content': 'FINDINGS:\\n\\n*   **Liver/Spleen**: No obvious lacerations or hematomas are visualized in the liver or spleen based on the provided images.\\n*   **Abdomen**: Free fluid in the peritoneal cavity is visualized.\\n*   **Other**: The images show areas of interest within the abdominal cavity.\\n\\nBased on the provided images, the following findings are identified:\\n\\n*   **Free fluid**: Free fluid is present in the peritoneal cavity, indicated by the bounding boxes highlighted in the images.\\n*   **Liver/Spleen**: No findings are specifically noted in the liver or spleen.\\n\\nRecommendations:\\n\\n*   Based on the images, there is no indication of lacerations or hematomas in the liver or spleen.\\n*   There is free fluid in the abdominal cavity.\\n*   Further assessment and correlation with clinical information are required to determine the significance of these findings.'}]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"%%time\nimport pandas as pd\nimport os\n\n# 1. Load the labels (Adjust path to your folds/train csv)\ntrain_df = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/folds.csv')\n\ndef get_ground_truth(image_path):\n    # Extract patient_id from the path\n    # Path format: /kaggle/.../patient_id/series_id/filename\n    parts = image_path.split('/')\n    \n    # Adjust index depending on your specific folder structure\n    # Usually patient_id is the 2nd or 3rd to last folder\n    try:\n        patient_id = int(parts[-3]) \n        labels = train_df[train_df['patient_id'] == patient_id].iloc[0]\n        \n        print(f\"üìå GROUND TRUTH FOR PATIENT {patient_id}:\")\n        print(f\"Liver: {'Healthy' if labels.liver_healthy else 'Injured (Low/High)'}\")\n        print(f\"Spleen: {'Healthy' if labels.spleen_healthy else 'Injured (Low/High)'}\")\n        print(f\"Kidney: {'Healthy' if labels.kidney_healthy else 'Injured (Low/High)'}\")\n        return labels\n    except Exception as e:\n        return f\"Could not parse patient ID from path: {e}\"\n\n# Run it on your test image\ngt_labels = get_ground_truth(\"/kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/yolov8_roi_detection/experiment/val_batch0_pred.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:46:13.412071Z","iopub.execute_input":"2026-01-15T21:46:13.412405Z","iopub.status.idle":"2026-01-15T21:46:13.432975Z","shell.execute_reply.started":"2026-01-15T21:46:13.412377Z","shell.execute_reply":"2026-01-15T21:46:13.432019Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 6.37 ms, sys: 1.18 ms, total: 7.55 ms\nWall time: 14.9 ms\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%%time\nimport pandas as pd\nimport os\nimport glob\n\n# 1. Load the Baseline Scores\nscores_path = '/kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/baseline/scores.csv'\nscores_df = pd.read_csv(scores_path)\n\n# 2. Find any image file in your dataset to test the link\ndef find_all_images(root_dir):\n    # Support jpg, png, and dcm\n    valid_extensions = ('.jpg', '.png', '.dcm')\n    image_paths = []\n    for root, dirs, files in os.walk(root_dir):\n        for file in files:\n            if file.lower().endswith(valid_extensions):\n                image_paths.append(os.path.join(root, file))\n    return image_paths\n\n# 3. Map Image to Score\nall_imgs = find_all_images('/kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/')\n\nprint(f\"üìÇ Found {len(all_imgs)} images in total.\")\n\nif all_imgs:\n    sample_path = all_imgs[0]\n    print(f\"üîç Testing mapping for: {sample_path}\")\n    \n    # Extract ID (This is the 'Startup' way: iterate until it hits)\n    # Most Kaggle datasets use the filename or the parent folder as the ID\n    potential_id = os.path.basename(sample_path).split('.')[0].split('_')[-1]\n    \n    # Look for this ID in your scores_df\n    # We search the whole dataframe for any column containing this ID\n    match = scores_df[scores_df.astype(str).apply(lambda x: x.str.contains(potential_id)).any(axis=1)]\n    \n    if not match.empty:\n        print(\"‚úÖ Match Found in Baseline Scores!\")\n        print(match.head())\n    else:\n        print(f\"‚ùå ID {potential_id} not found in scores.csv. Let's look at the first few IDs in the CSV:\")\n        print(scores_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:46:35.321108Z","iopub.execute_input":"2026-01-15T21:46:35.321414Z","iopub.status.idle":"2026-01-15T21:46:35.525685Z","shell.execute_reply.started":"2026-01-15T21:46:35.321388Z","shell.execute_reply":"2026-01-15T21:46:35.524682Z"}},"outputs":[{"name":"stdout","text":"üìÇ Found 180 images in total.\nüîç Testing mapping for: /kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/yolov8_roi_detection/experiment/PR_curve.png\n‚ùå ID curve not found in scores.csv. Let's look at the first few IDs in the CSV:\n                 target  log_loss  sample_weighted_log_loss  accuracy  \\\n0          bowel_injury  0.105383                  0.167508  0.979663   \n1  extravasation_injury  0.671142                  0.682697  0.936447   \n2            any_injury  0.681792                  0.703257  0.728313   \n3                kidney  0.299856                  0.511072  0.942167   \n4                 liver  0.427419                  0.652512  0.897998   \n\n   precision    recall  specificity        f1  roc_auc  average_precision  \n0   0.000000  0.000000          1.0  0.000000      0.5           0.020337  \n1   0.000000  0.000000          1.0  0.000000      0.5           0.063553  \n2   0.000000  0.000000          1.0  0.000000      0.5           0.271687  \n3   0.314056  0.333333          NaN  0.323408      NaN                NaN  \n4   0.299333  0.333333          NaN  0.315419      NaN                NaN  \nCPU times: user 20.3 ms, sys: 5.48 ms, total: 25.8 ms\nWall time: 198 ms\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"%%time\nimport os\nfrom PIL import Image\n\n# 1. Filter for actual CT slice images (avoiding the .png curves)\nall_files = find_all_images('/kaggle/input/rsna-2023-abdominal-trauma-detection-dataset/')\n# We want the 'val_batch' images because they contain the actual patient data\nscan_images = [f for f in all_files if 'val_batch' in f and f.endswith('.jpg')]\n\nprint(f\"‚úÖ Found {len(scan_images)} patient scan samples for analysis.\")\n\n# 2. Clinical Report Generator Loop\nfor i, img_path in enumerate(scan_images[:3]): # Let's start with 3 samples\n    print(f\"\\nüìÑ GENERATING REPORT FOR SAMPLE {i+1}: {os.path.basename(img_path)}\")\n    \n    img = Image.open(img_path).convert(\"RGB\")\n    \n    # Advanced Clinical Prompt: Forcing the model into 'Radiologist' mode\n    report_prompt = \"\"\"Perform a formal radiological review of this abdominal CT slice.\n    - Assessment: Identify organs within the YOLO bounding boxes.\n    - Findings: Describe any density changes, lacerations, or fluid.\n    - Conclusion: Based on the visual evidence, what is the suspected injury grade?\"\"\"\n\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image\", \"image\": img},\n                {\"type\": \"text\", \"text\": report_prompt},\n            ],\n        },\n    ]\n\n    # Inference\n    output = pipe(messages, max_new_tokens=350)\n    \n    print(\"-\" * 40)\n    print(f\"ü©∫ MEDGEMMA REPORT {i+1}:\")\n    print(output[0]['generated_text'])\n    print(\"-\" * 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T21:48:17.354230Z","iopub.execute_input":"2026-01-15T21:48:17.354642Z","iopub.status.idle":"2026-01-15T21:49:23.080660Z","shell.execute_reply.started":"2026-01-15T21:48:17.354597Z","shell.execute_reply":"2026-01-15T21:49:23.079863Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"‚úÖ Found 6 patient scan samples for analysis.\n\nüìÑ GENERATING REPORT FOR SAMPLE 1: val_batch0_pred.jpg\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----------------------------------------\nü©∫ MEDGEMMA REPORT 1:\n[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1920x1808 at 0x7A18B662C8F0>}, {'type': 'text', 'text': 'Perform a formal radiological review of this abdominal CT slice.\\n    - Assessment: Identify organs within the YOLO bounding boxes.\\n    - Findings: Describe any density changes, lacerations, or fluid.\\n    - Conclusion: Based on the visual evidence, what is the suspected injury grade?'}]}, {'role': 'assistant', 'content': '- The image displays a series of CT slices focused on the abdomen.\\n- The bounding boxes highlight areas of interest.\\n- In the first image, the \"abdominal 1.0\" box highlights the stomach and the surrounding abdominal contents.\\n- In the second image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the third image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the fourth image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the fifth image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the sixth image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the seventh image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the eighth image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the ninth image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the tenth image, the \"lower 1.0\" box highlights the abdominal contents, with the lower portion of the stomach and surrounding structures.\\n- In the eleventh image, the \"lower 1.'}]\n----------------------------------------\n\nüìÑ GENERATING REPORT FOR SAMPLE 2: val_batch1_pred.jpg\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"----------------------------------------\nü©∫ MEDGEMMA REPORT 2:\n[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1920x1808 at 0x7A18B4237440>}, {'type': 'text', 'text': 'Perform a formal radiological review of this abdominal CT slice.\\n    - Assessment: Identify organs within the YOLO bounding boxes.\\n    - Findings: Describe any density changes, lacerations, or fluid.\\n    - Conclusion: Based on the visual evidence, what is the suspected injury grade?'}]}, {'role': 'assistant', 'content': 'I am unable to perform a formal radiological review of the provided image. I am unable to process images.\\n\\nHowever, I can provide a general assessment based on the name \"abdominal CT slice\" and the labels.\\n\\n- **Assessment:** The image is a CT scan of the abdomen. The YOLO bounding boxes likely highlight various anatomical structures.\\n\\n- **Findings:** Without a detailed description of the image, it is hard to find specific abnormalities.\\n\\n- **Conclusion:** Based on the name and the bounding boxes, it\\'s impossible to determine the injury grade. A trained radiologist would need to analyze the complete CT scan to provide a diagnosis.\\n'}]\n----------------------------------------\n\nüìÑ GENERATING REPORT FOR SAMPLE 3: val_batch2_labels.jpg\n----------------------------------------\nü©∫ MEDGEMMA REPORT 3:\n[{'role': 'user', 'content': [{'type': 'image', 'image': <PIL.Image.Image image mode=RGB size=1920x1920 at 0x7A18B6667620>}, {'type': 'text', 'text': 'Perform a formal radiological review of this abdominal CT slice.\\n    - Assessment: Identify organs within the YOLO bounding boxes.\\n    - Findings: Describe any density changes, lacerations, or fluid.\\n    - Conclusion: Based on the visual evidence, what is the suspected injury grade?'}]}, {'role': 'assistant', 'content': \"- **Assessment:** The images show abdominal CT scans with different regions highlighted by bounding boxes.\\n- **Findings:** The scans display various anatomical structures, including the liver, spleen, kidneys, and bowel. Some regions appear normal, while others show variations in density. There is no obvious evidence of lacerations or fluid collection in the provided images.\\n- **Conclusion:** Based on the visual evidence, it's difficult to determine a specific injury grade. More information would be needed to assess injury grade.\"}]\n----------------------------------------\nCPU times: user 1min 4s, sys: 1.02 s, total: 1min 5s\nWall time: 1min 5s\n","output_type":"stream"}],"execution_count":14}]}